---
title: "project update 2"
author: "Hongkai Wang"
date: "2022-11-07"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Question 1

**Group Number: **7

**Group Name: **Regression Heroes

**Group Members:**Ryan Wang, Stella Nam, Hongkai Wang

# Question 2
## Part a

Yes, we did a literature review of similar problems relating various cancer outcomes to socioeconomic factors. However, a lot of the studies that looked into the possible influence of socioeconomic factors on cancer outcomes are fairly recent and it appears that there needs to be more research into this relationship overall. Additionally, a lot of the research in this field was done using data from nations other than the US. 

There was a [**2018 paper published in JAMA**](https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2705856) that looked at county-level median incomes and cancer death rates in the US. They used a different dataset, data from the Institute for Health Metrics and Evaluation from 2014 along with the income data from the 2012 US Census Bureau Small Area Income and Poverty Estimates. The data were stratified into low-, medium-, and high-income groups. They used a single- and multiple-mediator model to assess changes in parameter estimates after adding potential mediators other than household income, such as smoking. They also used a multivariate normal regression model for sensitivity analysis. Although the main questions being posed by this paper is very similar to our project, we will that we can more variables we can consider that potentially influence cancer death rates as well as individual data, which can hopefully confirm the results from this study also provide more insight into these complex relationships between the covariates. We think the multiple-mediator model might be interesting to include in our project because there are multiple factors and potential mediators that likely result in cancer deaths. We can further study these complex relationships in our data using this model. 

Additionally, there was another paper published in [**Frontiers in 2022**](https://www.frontiersin.org/articles/10.3389/fonc.2022.827028/full) that looks at cancer-free life expectancy trends from 2006-2018 based on income inequalities using German Health Insurance Data. They used a proportional hazard regression model for their statistical analysis. This paper not only looked at cancer risk overall, but also looked into specific cancer outcomes, such as colon, stomach, and lung cancer based on gender. We feel that we can use the finding and potential factors from this paper such as gender and insurance coverage to assess cancer death rates in our dataset. 

There was a [**2018 paper published in PLoS One**][https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5819792/] specifically looking at lung cancer and socioeconomic status. This study used a pooled analysis of different case-control studies. Here, they looked at data from Europe and Canada. They used an unconditional logistic regression model as well as random-effect meta-regression models to assess this association. The paper concludes that SES is a risk factor for lung cancer after adjustment for smoking behavior. However, a major limitation of this study was that they were not able to adequately control smoking behavior, which is one of the leading causes of lung cancer. Although the conclusions from the study are interesting as the authors are studying topics similar to our project topic but in different countries, the models and methods used in this study do not apply to our project.

## Part b

Yes, we received our peers’ and the Teaching Team’s reviews of our 1st Project Check-in. 

From our peers, we received a few comments about looking at more biologically-grounded factors such as health conditions and genetics on the risk of cancer deaths. Although we do not think these factors aligned with the purpose of our research questions since we are trying to assess the influence of SES factors, we think it would be interesting if we overlay our results from our analysis to the existing literature on cancer outcomes based on genetics or other biological markers at the end. 

There were also a few concerns about the data being generalized to all cancers rather than specific cancers. Based on our prior education knowledge and reviewing the literature, we agree that a lot of cancer outcomes vary greatly based on the specific type of cancer. Some cancers are also more treatable than others, resulting in a lower death rate on average. However, there was also a comment from one of our other reviewers regarding our outcome variable. They correctly identified that the data was specific to lung cancer data rather than cancer generally. Going forward, we will take that into account in our analysis, specific to lung cancer.

The peer reviewers also mentioned that we should focus on key variables such as income since socioeconomic factors are very vague. Upon our EDA, we can on focusing on the variables that seem most correlated with cancer death rates overall, which include but are not limited to median income, median age, and public coverage. 

From the teaching team, we had a comment about whether we wanted to predict cancer-related death or consider the association between cancer-related death and one or a limited number of exposures. Upon doing more research into lung cancer, we think it would be more appropriate to explore the latter. This is because there is already strong evidence in the literature suggesting that lung cancer has a strong association with environmental factors such as smoking. These factors are not included in our data, nor is it the purpose of our project. Additionally, socioeconomic influences are not well understood in lung cancer incidence and death. Thus, trying to understand the association between cancer deaths and certain socioeconomic factors is something we are trying to explore with our project. 

Lastly, we did not contact any non-teaching team domain experts because we stated in our first project check-in that we thought it was not necessary for the scope of our project. Upon conducting a literature review and reviewing our peers’ and Teaching Team’s reviews, we stand by this decision. 

# Question 3

At the moment, we do not have too many changes we want to make to our analysis plan. Changes to our plan is shown in \textcolor{blue}{blue}.

**Exploratory Data Analysis:**

* Better understand the structure and complexity of our data set through str and summary functions in R
* Check for missing data points categorized by different covariates (by employment status of different age groups)
* Explore data patterns and modeling – Check for correlation between different socioeconomic status determining variables and cancer prevalence through a pairs plot.
  * One of the variables of interest of our project is the effect of region/state on cancer prevalence. Graph this relationship to observe for any patterns.
  
**Primary Inference Problem:**

* Poisson regression (within a generalized linear framework) will be our main modeling approach for statistical inference due to our primary outcome being rate/count data \textcolor{blue}{on lung cancer death.}
* With 33 covariates of interest, we will need to employ model selection techniques, potentially finding a good in-between for various automated methods and integrating domain information
* Once we have identified some covariates of interest, we will perform various smoothing methods in order to determine the relative correlations in data
  * \textcolor{blue}{Currently, based on our EDA and project checkins, median income, median age, and public health coverage seem like good potential factors we can include as SES. Additionally, we are continually updating our dataset with other factors we believe are revelant to our primary and secondary questions such as data on politcal preference and education attainment data.}
* Data cleaning and computing additional predictors (e.g., regions, climate... )
  * \textcolor{blue}{Given that we have a lot of missing data, especially for the college education section, we will discard this data as it will be difficult to address and work with data where so much of it is missing. (more  on this in question 4)}
  * \textcolor{blue}{For insurance data where we have around 20 percent missing data, we will perform a sensitivity analysis by viewing models under complete cases, under imputation, and under other missing data methods such as inverse proportional weighting.}
* As our data is on the county-level, we aim to add a dimension to our analysis by aggregating these data onto the state-level, which would allow us to study state-by-state differences in socioeconomic conditions and cancer outcomes
* Create comprehensive visualization of our demographic data to illustrate
differences between US counties and states
* We will explore different imputation techniques to adjust for the 3046 incomplete observations in these data
* Identify and adjust for potential confounders (on the association of SES to cancer prevalence) such as, but not limited to, county and income.
* For any of these covariates which we are not interested in interpreting, we aim to adjust for them flexibly using splines/GAMs (and if not needed, we will keep using linear terms)

**Secondary Inference Problem:**

* We are potentially interested in looking at state-level and county-level differences in demographics and insurance status
* Here we will employ multinomial models in order to model the probability of some set of socioeconomic conditions and cancer outcomes being in a given county or state
* \textcolor{blue}{We are also interested in looking at the relationship between socioeconomic status and political preference of different demographic groups. We will find an additional data on voting outcomes from a recent US election and merge that with our current dataset. Since the US elections use a bipartisan system, we can use logistic linear regression to understand this relationship.}

**Predictive Problem:**

* Aside from the inference problem, we are also interested in the prediction problem and if there is time, we will explore the performance of our generalized linear models on prediction metrics (accuracy, AUC, etc.)
* We will also explore how penalized models (LASSO, Ridge, Elastic Net) and traditional ML algorithms (random forests/basic nnets for primary analysis, RFs/KNN/nnets/etc. for secondary analysis tasks) compare with the inference models we previously built
* Here we are also interested in exploring how the number of predictors can correlate with generalizability in these 3 forms of models
```{r, echo = F}
library(tidyverse)
library(stringr)
library(viridisLite) # nice colours
```


# Exploratory Data Analysis

```{r, echo = F}
dat <- read_csv("data/cancer_reg.csv")
str(dat)
#summary(dat)
ed <- read_csv("data/Education.csv")
states <- read_csv("data/50_states.csv") %>% 
    add_row(State="District of Columbia", Abbr="DC", `State Capital`="Washington", Region="East")
```

```{r, echo = F}
# get county names
dat <- dat %>% 
    mutate(county_name = str_split(Geography, ",") %>% map_chr(., 1))%>%
    mutate(state = str_extract(Geography, "[^,]+$")) %>% # regex to select everything after ','
    mutate(state = str_trim(state)) %>%
    left_join(states, by=c("state" = "State")) %>%
    filter(county_name != "Valdez-Cordova Census Area")

Encoding(dat$county_name) <- "UTF-8"
dat$county_name <- iconv(dat$county_name, "UTF-8", "UTF-8", sub='')
dat <- dat %>%
    mutate(county_name = ifelse(county_name == "Doa Ana County", "Dona Ana County", county_name))

# get education stats from 2016-2020 https://www.ers.usda.gov/data-products/county-level-data-sets/download-data/
ed <- ed %>%
    filter(grepl("2016", Attribute)) %>%
    rename(county_name = `Area name`) %>%
    pivot_wider(names_from = Attribute, values_from = Value)  %>%
    mutate(county_name = case_when(county_name == "La Salle County" & State != "TX" ~ "LaSalle County",
                                   county_name == "La Salle Parish" ~ "LaSalle Parish",
                                   TRUE ~ county_name))

dat <- ed %>%
    right_join(dat, by=c("county_name", "State" = "Abbr")) %>%
    distinct()
```

## How much missing data is there?

```{r, echo = F}
no_geodat <- dat %>% select(-c("Geography", "State Capital", "Region", "state", "State", "county_name", "binnedInc")) # no missing counties
no_geodat[!complete.cases(no_geodat),] %>%  # keep rows with NAs
    pivot_longer(colnames(no_geodat), names_to = "Covariates", values_to = "Values") %>% # pivot into long table
    filter(is.na(Values)) %>% # filter out all the non-na's
    ggplot(aes(x = Covariates)) + 
    geom_bar(position = "dodge", aes(col = Covariates, fill = Covariates)) + 
    theme_bw() + 
    # scale_fill_viridis_d() + 
    # scale_color_viridis_d() + 
    theme(axis.text.x = element_blank())
```
Interestingly, there is some missing data in the reporting of county employment for residents age 16 and over. We observe more missing data in percentages of county residents with only private healthcare coverage, and missing data in the majority of counties for reports of the percent of county residents between 18 and 24 years old with with some college as their highest attained education. One hypothesis for why there may be a large amount of missing data in educational reporting for 18 to 24 year olds with some college may be because some counties may not have high emphasis on higher education and many individuals in this age range that are pursuing college will probably be in more college-oriented counties.

```{r, echo = FALSE, fig.height = 5, fig.width = 8}
# NAs grouped by education
p1a <- dat[!complete.cases(dat),] %>%  # keep rows with NAs
    pivot_longer(colnames(ed)[8:11], names_to = "Education", values_to = "Values") %>% # pivot into long table
    filter(is.na(PctEmployed16_Over)) %>% # filter out all the non-na's
    ggplot(aes(x = Education, y = Values)) + 
    geom_boxplot(show.legend = F, outlier.shape = NA) +
    geom_point(aes(col = State), position = position_jitterdodge(jitter.width=0, dodge.width = 0.3)) + 
    theme_bw() + 
    theme(axis.text.x = element_text(angle = 90, hjust=1)) + 
    labs(y = "Percent of adult population", title = "Distribution of Education Among NA percent employed 16 and over")
    # scale_fill_viridis_d() + 
    # scale_color_viridis_d() + 

p1b <- dat[complete.cases(dat),] %>%  # keep rows with NAs
    pivot_longer(colnames(ed)[8:11], names_to = "Education", values_to = "Values") %>% # pivot into long table
    filter(!is.na(PctEmployed16_Over)) %>% # filter out all the non-na's
    ggplot(aes(x = Education, y = Values)) + 
    geom_boxplot(show.legend = F, outlier.shape = NA) +
    geom_point(aes(col = State), position = position_jitterdodge(jitter.width=0, dodge.width = 0.3)) + 
    theme_bw() + 
    theme(axis.text.x = element_text(angle = 90, hjust=1)) + 
    labs(y = "Percent of adult population", title = "Distribution of Education Among complete percent employed 16 and over")

gridExtra::grid.arrange(p1a, p1b, ncol = 2)
```
```{r, echo = F, fig.height = 5, fig.width = 8}
# NAs grouped by education
p1a <- dat[!complete.cases(dat),] %>%  # keep rows with NAs
    pivot_longer(colnames(ed)[8:11], names_to = "Education", values_to = "Values") %>% # pivot into long table
    filter(is.na(PctSomeCol18_24)) %>% # filter out all the non-na's
    ggplot(aes(x = Education, y = Values)) + 
    geom_boxplot(show.legend = F, outlier.shape = NA) +
    geom_point(aes(col = State), position = position_jitterdodge(jitter.width=0, dodge.width = 0.3)) + 
    theme_bw() + 
    theme(axis.text.x = element_text(angle = 90, hjust=1)) + 
    labs(y = "Percent of adult population", title = "Distribution of Education Among NA percent some college education 18-24")
    # scale_fill_viridis_d() + 
    # scale_color_viridis_d() + 

p1b <- dat[complete.cases(dat),] %>%  # keep rows with NAs
    pivot_longer(colnames(ed)[8:11], names_to = "Education", values_to = "Values") %>% # pivot into long table
    filter(!is.na(PctSomeCol18_24)) %>% # filter out all the non-na's
    ggplot(aes(x = Education, y = Values)) + 
    geom_boxplot(show.legend = F, outlier.shape = NA) +
    geom_point(aes(col = State), position = position_jitterdodge(jitter.width=0, dodge.width = 0.3)) + 
    theme_bw() + 
    theme(axis.text.x = element_text(angle = 90, hjust=1)) + 
    labs(y = "Percent of adult population", title = "Distribution of Education Among complete some college education 18-24")

gridExtra::grid.arrange(p1a, p1b, ncol = 2)
```

```{r, fig.height = 5, fig.width = 8, echo = F}
# NAs grouped by education
p1a <- dat[!complete.cases(dat),] %>%  # keep rows with NAs
    pivot_longer(colnames(ed)[8:11], names_to = "Education", values_to = "Values") %>% # pivot into long table
    filter(is.na(PctPrivateCoverageAlone)) %>% # filter out all the non-na's
    ggplot(aes(x = Education, y = Values)) + 
    geom_boxplot(show.legend = F, outlier.shape = NA) +
    geom_point(aes(col = State), position = position_jitterdodge(jitter.width=0, dodge.width = 0.3)) + 
    theme_bw() + 
    theme(axis.text.x = element_text(angle = 90, hjust=1)) + 
    labs(y = "Percent of adult population", title = "Distribution of Education Among NA percent alone private coverage")
    # scale_fill_viridis_d() + 
    # scale_color_viridis_d() + 

p1b <- dat[complete.cases(dat),] %>%  # keep rows with NAs
    pivot_longer(colnames(ed)[8:11], names_to = "Education", values_to = "Values") %>% # pivot into long table
    filter(!is.na(PctPrivateCoverageAlone)) %>% # filter out all the non-na's
    ggplot(aes(x = Education, y = Values)) + 
    geom_boxplot(show.legend = F, outlier.shape = NA) +
    geom_point(aes(col = State), position = position_jitterdodge(jitter.width=0, dodge.width = 0.3)) + 
    theme_bw() + 
    theme(axis.text.x = element_text(angle = 90, hjust=1)) + 
    labs(y = "Percent of adult population", title = "Distribution of Education Among complete percent alone private coverage")

gridExtra::grid.arrange(p1a, p1b, ncol = 2)
```

```{r}
#colMeans(is.na(no_geodat))*100
```


```{r, echo = F}
ed_missing <- setdiff(unique(ed$county_name), unique(dat$county_name))
filter(ed, county_name %in% ed_missing)
dat_missing <- setdiff(unique(dat$county_name), unique(ed$county_name))
filter(dat, county_name %in% dat_missing)
```
Here we show some difference in county representation within our two integrated cancer trial and socioeconomic dataset with a dataset of education attainment by county. Notably, a large difference in the counties from both datasets is the inclusino of Puerto Rico. While the education dataset includes Puerto Rico, the cancer trial data set does not. This means this missing data is **MAR** for our primary inference since it depends on a covariate *State* (or **MNAR** for our secondary as county is an outcome), however we will consider our analysis without Puerto Rico as it is a unique situation and not localized to the North American land mass. Other missing cancer data are at the county level, not found in the education dataset, similarly, as we are focused on the cancer data, we will disregard these education data (as we have education data for all cancer-statistic counties we have). 

## Exploring data patterns and modeling

```{r, fig.width=10, fig.height=10, echo = F}
#pairs(dat %>% select(where(is.numeric)))
```


### Look at the state-wide view

```{r, echo = F}
dat %>%
    ggplot(aes(x = state, y = avgDeathsPerYear, colour = state, fill = state)) +
    geom_boxplot() + 
    theme_bw() + 
    coord_flip()
```


## 4. Missing data
### a.
Overall, our data contains 19.9869% data missing from private health insurance coverage alone, 4.9885%% data missing from percent of individuals 16 or over that are employed, and 74.9918% data missing from percent of individuals who have some college education between ages of 18 to 24. 

We believe the missing private health insurance data is *MAR* due to the fact that some other counties in the same state have this data, and the individual who created this data set did not include the processing scripts for insurance data. This leads me to believe the most probable reason for these missing data are due to not carefully checking for missing data. Due to it being 19.9869% missing, We don't believe we can simply disregard this data, as such we will need to formally address it via some missing data methods. 

With similar reasoning, we believe the 4.9885% missing data from percentage of employed individuals 16 or over and 74.9918% missing data from percentage of individuals with some college education between ages 18 to 24 are also *MAR*. Especially with the college education, we found external census data on the county-level providing education data, reinforcing the belief that the original data was lost through data processing, perhaps due to issues like attributes not matching on data set joins. 

### b.
For the 4.9885% missing data from percentage of employed individuals 16 or over and 74.9918% missing data from percentage of individuals with some college education between ages 18 to 24, we will drop the missing data. This is because the employement data is still under the 5% threshold by rule-of-thumb, and should not have a huge impact on biasing our resulting estimates. Due to the large amount of missing data in the education attribute, we will simply drop that attribute, as we do not believe we would be able to get a meaningful analysis using it anyways (with or without missing data methods).

For the 19.9869% of missing insurance data, we will perform a sensitivity analysis. That is, viewing models under complete cases, under imputation (mean, EM, random forest), and under other missing data methods such as inverse proportional weighting. We will also explore these methods conditional on the states, as we believe that counties within a state are more likely to be similar to each other as they are geographically similar, and share state-level policies, which would likely influence the socioeconomic attributes within a county.

## 5. Modelling Approches

### a. Fitting an linear model


```{r, echo = F}
#load data
library(tidyverse)
library(tidyr)
library(ggplot2)

#this line is for setting file path on Bruce's home pc. 
#setwd("C:\\Users\\Bruce\\Desktop\\classes\\bst210")
#dat = read_csv("data/cancer_reg.csv")
```
Linear regression models hold a special position in the world of statistics, as it is one of the oldest, and the most tried-and-true method of models. For the purpose of this project, linear models, both GAM and multiple regression, serve as an valuable and important introduction to the exploration of the dataset. Our data set contains information on the socioeconomic status, lung cancer death rate, demographic, etc. of US counties. If we view cancer death rate as an continuous variable outcome, we can most certainly derive very useful information on the relationship between social factors and the cancer death rate within different US counties. 

Our main interest in the data set is whether we can derive some useful relationship between the social-economic status of US counties, and their lung cancer-related death rate. In our data set, the lung cancer-related death rate is specifically defined to be the Mean per 100,000 citizen lung cancer mortality over the data collection period (2010 -2016, with exception of the additional education data that was collected in 2020). Before we formally think about the model structure, we should first define our set of social economic status indicators. 

Several co-variates from our data is specifically useful in defining the social-economic status of a region. First, median income is a key predictor as it is often used by economists in their evaluation of the wealthiness of a region. Second, median age is an important demographic descriptor in two sense. Median age can describe both the likelihood to get lung cancer (older people are more susceptible to cancer) and the wealth level of the county (older people are more likely to be richer). Third, percentage of white people in each county could also be useful in defining the social-economic status of the region, as historically, white neighborhoods are more likely to be better funded, and thus result in better healthcare conditions. With these indicators in mind, let's first explore a multiple linear regression model. 

#### Model assumptions: 
Since our data are sourced from census, and goverment sources, we have reason to believe that each predictor variables following the central limiting theorem (each covariate entry is the mean over multiple years samples), and the LINE assumptions should be met. 

#### data transformation and cleaning: 

```{r, echo = F}
hist(dat$medIncome)
hist(dat$PctWhite)
hist(dat$MedianAge, breaks = 100)
```
we see that there are some insanely high median age here. These has to be errors in data collection or imputing process as it is improbable to have median ages that high. let's remove these rows of data for now. 

```{r, echo = F}
dat = dat %>% filter(MedianAge <= 100)

hist(dat$MedianAge, breaks = 100)
```

The other two variables are skewed, but they should be workable. I am not normalizing the income data as the interpretability is a bit better this way. 

#### model fitting:

```{r, echo = F}
mod1 = lm(data = dat, TARGET_deathRate ~ medIncome + MedianAge + PctWhite)
summary(mod1)
```

Based on the model summary, we can see that median age is not a significant predictor of lung cancer death rate itself, which is a bit surprising based on previous assumptions. However, it could act still act as a confounder or effect modifier for our model. At the same time, it is good to see that both median income and the percentage of white population within a county is significantly correlated with lung cancer death rate. However, as previously illustrated, median age could also be a confounder to median income. Thus, let's quickly do some tests on whether median age is a confounder here. 

```{r, echo = F}
mod1.1 = lm(data = dat, TARGET_deathRate ~ medIncome + PctWhite)
summary(mod1.1)
anova(mod1.1, mod1)
```

We see that removing median age doesn't affect the coefficients of the two other covariates at all. And LRT result supports this finding. 

```{r, echo = F}
mod1.2 = lm(data = dat, TARGET_deathRate ~ medIncome + PctWhite + MedianAge + medIncome*MedianAge)
summary(mod1.2)
anova(mod1.2, mod1)

mod1.3 = lm(data = dat, TARGET_deathRate ~ medIncome + PctWhite + MedianAge + PctWhite*MedianAge)
summary(mod1.3)
anova(mod1.3, mod1)
```


Unfortunately, we can see that median age doesn't really play any part as the effect modifier of median income or percentage of white population in the model. At this point, we can decide that for the linear model, we can clearly define the two core descriptor of social economic status is median income and percentage of white population. let's expand a bit more here. First, I will include the precentage of white, black, asian, and other race percentage into the model to see if we can increase the predictive power of the model. 

```{r, echo = F}
mod1.4 = lm(data = dat, TARGET_deathRate ~ medIncome + PctWhite + PctBlack + PctAsian + PctOtherRace)
summary(mod1.4)
```

We see that the adjusted R-squared value of model 1.4 is higher than model 1.3 and it is beneficial to include a fuller description of the racial distribution. However, we can also see that the Asian and Black percentages are not very significant. By definition, there should be some interactions between these percentages, and it is worth it to check it out. 

```{r}
cor(dat$PctAsian, dat$PctWhite)
cor(dat$PctBlack, dat$PctWhite)
cor(dat$PctOtherRace, dat$PctWhite)
```

We see that the value of PctBlack and PctWhite are strongly negatively correlated, and the other two percentages are weakly correlated. Thus, we should remove PctBlack from the model to reduce colinearity. 

```{r, echo = F}
mod1.5 = lm(data = dat, TARGET_deathRate ~ medIncome + PctWhite + PctAsian + PctOtherRace)
summary(mod1.5)
anova(mod1.5, mod1.1)
```

After removing the PctBlack covariate, we see that there is a significant increase in adjusted R-squared value to mod1.1(baseline) and LRT results suggest the models are significantly different from each other. Let's take another look at the median income covariates again. My main interest here is that whether a quadratic term would benefit our model, as a income could have diminishing return effect on lung cancer prevention/death rate. 

```{r, echo = F}
mod1.6 = lm(data = dat, TARGET_deathRate ~ medIncome)
summary(mod1.6)
mod1.6.1 = lm(data = dat, TARGET_deathRate ~ medIncome + I(medIncome ^2))
summary(mod1.6.1)
anova(mod1.6, mod1.6.1)

predict = data.frame(TARGET_deathRate = predict(mod1.6.1, dat), medIncome = dat$medIncome)

dat %>% ggplot(aes(medIncome, TARGET_deathRate)) + geom_point() + geom_smooth(method = "lm") + geom_line(data = predict, aes(medIncome,TARGET_deathRate ), color = "red")
```

Judging from summary output, the quadratic model performs better than the purely linear model (based on adjusted R-squared value) and the two models are statistically different. However, a visual inspection of the data doesn't really show that the quadratic model is significantly better. At this point, we decide to keep the quadratic term due to the diagnostic stats. 

We now have this following core model: 
```{r, echo = F}
mod1_core = lm(data = dat, TARGET_deathRate ~ medIncome + I(medIncome ^2)+ PctWhite + PctAsian + PctOtherRace)
summary(mod1_core)

```

let's evaluate the residual diagnostic to confirm the model's validity. 


```{r, echo = F}
standardized_res = rstandard(mod1_core)
scatter.smooth(standardized_res, main = "standardized residual")
qplot(standardized_res, binwidth = 0.2)

qqnorm(standardized_res, pch = 1, frame = FALSE)
qqline(standardized_res, col = "steelblue", lwd = 2)
```

The model looks good, and the qqplot of the standardized residual plot only deviates from the straight line at the two edges. Thus, in conclusion, our core model is a good place to start for our future work. 

#### future work and direction

As mentioned in the missing data section, the education data is largely missing and we weren't able to directly add them to our analysis. We have acquired further information on the education level of each US county (data sourced from a 2020 study). However, the integration of the new data into our data set requires additional cleaning and this process will be conducted at a later time point. Furthermore, we are also looking to incorporate the insurance information of the US counties into the linear model. 

We are considering using GAM models in our future exploration as well. Using different smoothing methods could improve the performance of our models, and we are definitely interested in testing them out.

After we include all of the variables that we are interested in, we will preform Lasso, ridge, and elastic net models to reduce the overfitting and deciding on our final linear model. As we increase the number of predictor variables, we are expecting that some of them might be excluded from the final model during the either the lasso or the elastic net fitting process. 


### b. Logistic/multinomial/ordinal regression

Logistic/multinomial/ordinaln does not really fit into the exploration of our primary goals, as the lung-cancer death count can be mostly view as either a count statistics or a continuous outcome. However, there are several thing that we could do to incorporate Logistic/multinomial/ordinal regression into our project. 

First, we can split the lung-cancer death rate into several categories to broadly access the healthcare system at each county. For example, we can artificially create three different categories in the death rate variable. Let's take a look at the death rate distribution. 


```{r, echo = F}
hist(dat$TARGET_deathRate, breaks = 100)
```

We can make three bins, deathrate < 150, 150 <= deathrate < 200, 200 <= deathrate, and use them as a proxy to the quality of lung cancer prevention and quality of cancer care for each US county. But in fairness, the use of logistic regression in this case wouldn't benefit us too much as it doesn't really bring any new insight to our analysis. The previous linear model already provides a fine baseline in assess the same information for each US county. The normal distribution of lung cancer death rate also suggests that dividing outcomes into bins doesn't really benefit us with our primary goal. 

But let's do it anyway to test it out anyway. 


```{r, echo = F}
#create the three bins
dat = dat %>% mutate(multi = case_when(TARGET_deathRate < 150 ~ 1, TARGET_deathRate < 200 ~ 2, T ~ 3))
# 3 is bad quality lung cancer prevention, 2 is medium, 1 is good quality.  
```



```{r, echo = F}
library(nnet)
mod2.1 <- multinom(multi ~ medIncome + I(medIncome ^2), data = dat)
summary(mod2.1)
```

```{r, echo = F}
plot(mod2.1$fitted.values[,1][order(dat$medIncome)] ~ sort(dat$medIncome), type="l", col="dodgerblue", xlab=c("Median Income"), ylab="Predicted Probability", ylim=c(0,1))
points(mod2.1$fitted.values[,2][order(dat$medIncome)] ~ sort(dat$medIncome), type="l", col="magenta")
points(mod2.1$fitted.values[,3][order(dat$medIncome)]~sort(dat$medIncome), type="l", col="green")
```

we see that as median income increases, the county is much more likely to fall into the category 1, which is county with low lung cancer death rate. We can do the same with percentage of white citizens in the county as well. 



```{r, echo = F}
mod2.2 <- multinom(multi ~ PctWhite , data = dat)
summary(mod2.2)


plot(mod2.2$fitted.values[,1][order(dat$PctWhite)] ~ sort(dat$PctWhite), type="l", col="dodgerblue", xlab=c("Percentage of white residents"), ylab="Predicted Probability", ylim=c(0,1))
points(mod2.2$fitted.values[,2][order(dat$PctWhite)] ~ sort(dat$PctWhite), type="l", col="magenta")
points(mod2.2$fitted.values[,3][order(dat$PctWhite)]~sort(dat$PctWhite), type="l", col="green")
```

We see that percentage of white resident has less impact on the categorization of the county. 

However, we can see that this type of multinomial regression is less interesting than the linear model, as we are grossly categorizing the outcome variables. 
Thus, we have decided to take the logistic regression to another direction. Logistic regression could serve as an excellent method for the exploration of our secondary goals. 

One possible direction that we could take is to explore socioeconomic status and political tendencies. The US bipartisan system provides a excellent binary outcome for our logistic models. We could decide whether what would drive the county to vote for either candidates. To explore this topic, we would need to find additional data on the voting outcomes of 2016 on a county level and merge with our existing data set. This exploration will have to be conducted at a later time after we find a trustworthy and accurate data source. Currently, the politico site serves as the preliminary source for our data as it contains detailed county level voting outcomes. Source: https://www.politico.com/2016-election/results/map/president/. 

Additional data wrangling is required before we move forward with the Logistic/multinomial/ordinal regression analysis. Our current plan for the regressions invovles using the covariates from the previous linear models and develop our model from there. We think that the logistic regression model would be helpful in showing the political preference of different demographic groups. 



### c. Poisson Regression

### Over-dispersion
```{r, echo = F}
hist(dat$TARGET_deathRate, freq = F, ylim = c(0, 0.04))
lines(as.integer(min(dat$TARGET_deathRate)):as.integer(max(dat$TARGET_deathRate)), dpois(as.integer(min(dat$TARGET_deathRate)):as.integer(max(dat$TARGET_deathRate)), lambda = mean(dat$TARGET_deathRate)))
```
```{r, echo = F}
print(mean(dat$TARGET_deathRate))
print(var(dat$TARGET_deathRate))
```

```{r, echo = F}
hist(dat$avgAnnCount/dat$popEst2015, freq = F)#, ylim = c(0, 0.04))
lines(as.integer(min(dat$avgAnnCount/dat$popEst2015)):as.integer(max(dat$avgAnnCount/dat$popEst2015)), dpois(as.integer(min(dat$avgAnnCount/dat$popEst2015)):as.integer(max(dat$avgAnnCount/dat$popEst2015)), lambda = mean(dat$avgAnnCount/dat$popEst2015)))
```
```{r}
mean(dat$avgDeathsPerYear/dat$popEst2015)
var(dat$avgDeathsPerYear/dat$popEst2015)
```

```{r, echo = F}
hist(dat$incidenceRate, freq = F, ylim = c(0, 0.02))
lines(as.integer(min(dat$incidenceRate)):as.integer(max(dat$incidenceRate)), dpois(as.integer(min(dat$incidenceRate)):as.integer(max(dat$incidenceRate)), lambda = mean(dat$incidenceRate)))
```
```{r, echo = F}
print(mean(dat$incidenceRate))
print(var(dat$incidenceRate))
```
We notice for each of our potential target variables, while the Poisson density roughly fits, they are overdispersed. This suggests the potential of modelling our outcome of interest using an extension of the Poisson model. Due to not having zero-inflated data, this narrows down potentially modelling approaches to the Negative Binomial regression, which should account for over-dispersion, to make sure we do not have overconfident estimates. For these data, we do not need to account for lag as they are all averaged over the same time period for each covariate and outcome respectively. 

We would not need to modify our data at all to perform a Negative Binomial regression as our data is already in counts or rate form. Although one potential modification we might do is see how the regression turns out modelling the rate per 100 000 (our target of interest), and the pure count itself adjusting for population.

### Model fits
```{r, warning = FALSE, echo = F}
# poisson fit
state_inc_pop_pois <- dat %>% glm(formula = TARGET_deathRate ~ medIncome + State + popEst2015, family=poisson(), data=.)
summary(state_inc_pop_pois)

# neg bin fit
state_inc_pop_nb <- dat %>% MASS::glm.nb(formula = TARGET_deathRate ~ medIncome + State + popEst2015, data=.)
summary(state_inc_pop_nb)
```

Here we find that the negative binomial regression has slightly higher standard errors and resulting test statistics compared to the standard Poisson regression. This is as we expected since it suggests that the standard Poisson regression may cause overconfidence in model evaluations, due to the property of $\mathbb{E}[Y] = Var(Y)$ being unsatisfied.

Furthermore, we can interpret the Negative Binomial regression supposing median income is our covariate of interest. For a 1000 dollar increase in median income, a county has an estimated `exp(coef(state_inc_pop_nb)[[2]])` times the incident rate compared to if a county did not have a 1000 dollar increase in median income, on average, holding all other covariates fixed. This was a significant relationship as well, suggesting that median income may be negatively associated with the incidence rate of lung cancer deaths, however this is only a very slight relationship at `exp(coef(state_inc_pop_nb)[[2]])` with these covariates in this model, according to these data.

### d. Survival Analysis

We are not going to incorporate survival analysis into our project. This is because we do not have any time-to-event related relationships in our data. Furthermore, we cannot really reproduce these relationships using a modification of our variables since they are all aggregates over a time period, and so we cannot infer the individual-level observations to re-create time-to-event data.


# Question 6
## Abstract 

Lung cancer is one of the leading causes of global cancer incidence and mortality, accumulating over 1.8 million deaths each year. Lung cancer has become the second most common forms of cancer diagnosis for both men and women (Thandra et al). Although the incidence rate and mortality rate of lung cancer has been decreasing in the US due to public education and tobacco control policies (De groot et al), a better understanding of the disease within the socialeconomic and demographic context is still required to provide future guidance on combating the prevalent form of cancer. Data from US census, county level reports, and various government agencies were collected to create tabular data on lung cancer death rate, social economic status, demographic information, education level, and medical insurance information on the US county level. The primary goal of the project is to create a explanatory model between social economic status and the lung cancer death rate of each US county. A secondary goal of this project is to predict the political inclination of each county base on the existing data set using logistic regression models. 

Our primary goal would be achieved using two regression models, linear regression and poisson regression. The two methods were chosen due to possible different interpretation of the interested outcome, the lung cancer related death rate of each US county. Comprehensive models from the two methods were constructed and the final models are shown below: 

*insert final model here* 

The comparison of the two models results in the selection of ___ as the final model. We have found several significant factors within the model that provide significant context and utility to increasing health care equity in the United states. There factors and their interpretation are listed below: 


*insert table of important factors here. Will include name of covariates, model coefficient, interpretation* 

We also found some additional conclusions without our secondary goals. And these are our findings. 

*conclusion section* 
We will talk about the potential implication of our findings in a public health context, what future directions that we could take. And any potential shortcomings of our approach. 


Citations:

1. Thandra, Krishna Chaitanya et al. “Epidemiology of lung cancer.” Contemporary oncology (Poznan, Poland) vol. 25,1 (2021): 45-52. doi:10.5114/wo.2021.103829
2. de Groot, P. M., Wu, C. C., Carter, B. W., & Munden, R. F. (2018). The epidemiology of lung cancer. Translational lung cancer research, 7(3), 220–233. https://doi.org/10.21037/tlcr.2018.05.06


## Part b
**Introduction/Background:**

Lung cancer is one of the leading causes of global cancer incidence and mortality, accumulating over 1.8 million deaths each year. Lung cancer has become the second most common form of cancer diagnosis for both men and women (Thandra et al). The death rate of lung cancer is almost equal to the death rate of prostate, breast, and colon cancer combined in the United States (Dela Cruz and Tanoue). 

One of the known leading causes of lung cancer is cigarette and tobacco smoking. Not only does exposure to smoking suggest a strong link with lung cancer onset, but first- and second-hand exposure to tobacco smoke can have a genetic influence on individuals. The susceptibility of genetic markers to lung carcinogens as well as acquired epigenetic polymorphisms can drastically increase one's chances of being diagnosed with lung cancer. A family history of cancer, especially lung cancer, can also increase the risk for lung cancer in both smokers and non-smokers (Dela Cruz and Tanoue). 

Since the 1970s, there has been a drastic decrease in tobacco use in the US. 
Additionally, the exacerbated efforts to find genetic influences associated with lung cancer in recent years and the push for scientific insight into chemotherapy and pharmaceutical drugs to potential lung cancer treatments, have helped healthcare professionals find better ways to target and improve lung cancer prognosis (Lemjabbar-Alaoui et al). Therefore, the incidence rate and mortality rate of lung cancer have been decreasing in the US due to public education and tobacco control policies (De groot et al). However, a better understanding of the disease within the socioeconomically and demographic context is still required to provide future guidance on combating the prevalent form of cancer. With lower tobacco smoking rates in the US and an increasing prevalence of lung cancer in non-smokers, environmental factors as well as socioeconomic influences need to be further investigated.

**Data description and motivation:**

Data from the US census, county-level reports, and various government agencies were collected to create tabular data on lung cancer death rate, social economic status, demographic information, education level, and medical insurance information at the US county level. Specifically, the data used and analyzed is from [“OLS Regression Challenge - dataset by nrippner | data.world”](https://data.world/nrippner/ols-regression-challenge), which aggregates socioeconomic and clinical data from census.gov, clinicaltrials.gov, and cancer.gov. These cancer outcomes data were aggregated from cancer trials from 01/01/2010 through 06/01/2016 and socioeconomic and demographic data were aggregated from 2013 U.S. census data. Additionally, data from the [United States Department of Agriculture (USDA)](https://www.ers.usda.gov/data-products/county-level-data-sets/download-data/) was used to assess educational attainment as a potential factor associated with socioeconomic status. 

Given the lack of research on socioeconomic factors on cancer prevalence in the United States specifically, the dataset seemed appropriate for providing insight into the potential links between socioeconomic status and cancer overall. The primary goal of this study is to create an explanatory model between social economic status and the lung cancer death rate of each US county. A secondary goal of this project is to predict the political inclination of each county base on the existing data set using logistic regression models. A separate data set from [Politico](https://www.politico.com/2016-election/results/map/president/) was merged with the data from the US census to assess the secondary questions. 

**Citations**

1. Thandra, Krishna Chaitanya et al. “Epidemiology of lung cancer.” Contemporary oncology (Poznan, Poland) vol. 25,1 (2021): 45-52. doi:10.5114/wo.2021.103829
 
2. Dela Cruz CS, Tanoue LT, Matthay RA. Lung cancer: epidemiology, etiology, and prevention. Clin Chest Med. 2011 Dec;32(4):605-44. doi: 10.1016/j.ccm.2011.09.001. PMID: 22054876; PMCID: PMC3864624.

3. Lemjabbar-Alaoui H, Hassan OU, Yang YW, Buchanan P. Lung cancer: Biology and treatment options. Biochim Biophys Acta. 2015 Dec;1856(2):189-210. doi: 10.1016/j.bbcan.2015.08.002. Epub 2015 Aug 19. PMID: 26297204; PMCID: PMC4663145.

4. de Groot, P. M., Wu, C. C., Carter, B. W., & Munden, R. F. (2018). The epidemiology of lung cancer. Translational lung cancer research, 7(3), 220–233. https://doi.org/10.21037/tlcr.2018.05.06

## Part c

**Research and Analysis Methods:**

The data employed 34 potential covariates of interest related to socioeconomic and demographic factors. For our primary analysis, a Poisson regression model is employed to estimate the socioeconomic status-related incidence and mortality rates of lung cancer from our data. Furthermore, the data were stratified by state level to understand the state-by-state differences in socioeconomic conditions and lung cancer outcomes. To account for overdispersion, an extension of the Poisson model, the Negative Binomial regression, was used to prevent overconfident estimates. No further modifications were made to the data set to perform a Negative Binomial regression because the data was already in counts or rate form. 

Once we have identified some covariates of interest, various smoothing methods were utilized in order to determine the relative correlations in the data. (Please note, we have not finalized yet at this point in our project. However, one of the covariates we are considering is median income and the percentage of the white population within a county because it is significantly correlated with the lung cancer death rate. We also need to further study the potential confounders and effect modifiers within our potential covariates in our data set -- median age was considered in this project check-in. For the covariates we are not interested in interpreting in our final project, we plan to adjust for them flexibly using splines/GAMs).

For our secondary analysis, multinomial regression models were employed to model the probability of some set of socioeconomic conditions and cancer outcomes being in a given county or state in order to better understand state-level and county-level differences in demographics and insurance status. To investigate whether the political tendencies of different demographic groups could impact lung cancer outcomes, the logistic linear regression model was used. 

All the statistical analyses were carried out with R. The graphical visualization of the results was done in R using basic R and the package "tidyverse."

**Note:** We did not feel that we were ready to outline any results or discussion yet in our project.

# Question 8
At this moment in our project, we are not trying to reach a publication involving the work or results from this project. However, we agree that our research questions are data are important in the context of the research field of understanding connections between SES and cancer. That being said, if our project ends up resulting in interesting findings, we would be open to the idea of potentially publishing our results in some capacity. 
